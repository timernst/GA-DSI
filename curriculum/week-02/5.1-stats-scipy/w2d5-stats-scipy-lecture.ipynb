{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Stats Review & Intro to SciPy\n",
    "Week 2 | Lesson 5.1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "\n",
    "- Explain Type I and Type II errors\n",
    "- Explain t-testing and demonstrate it with scipy\n",
    "- Contrast t-testing with simulation solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LESSON GUIDE\n",
    "| TIMING  | TYPE  | TOPIC  |\n",
    "|:-:|---|---|\n",
    "| 10 min  | [Demo](#introduction)   | Significance levels, Type I and Type II errors  |\n",
    "| 10 min  | [Demo](#demo)  | Law of large numbers and central limit theorem  |\n",
    "| 10 min  | [Demo / Guided Practice](#demo)  | T-testing revisited  |\n",
    "| 20 min  | [Independent Practice](#ind-practice)  | T-testing  |\n",
    "| 10 min  | [Demo /Guided Practice](#demo)  | Computational approaches  |\n",
    "| 30 min  | [Independent Practice](#ind-practice)  |  Computational statistics |\n",
    "| 5 min  | [Conclusion](#conclusion)  | |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Significance levels, Type I and Type II errors\n",
    "\n",
    "Type I errors occur when the researcher rejects a null hypothesis when it is actually true. The probability of committing a Type I error is called the significance level, often denoted $\\alpha$.\n",
    "\n",
    "A Type II error occurs when the researcher wrongly accepts a null hypothesis that is false.  The probability of committing a Type II error is often denoted by $\\beta$.\n",
    "\n",
    "$$\\alpha\\ =\\ P(Reject\\ H_0\\ |\\ H_0\\ is\\ true) = P(Type\\ I\\ error)$$\n",
    "\n",
    "\n",
    "$$\\beta\\ =\\ P(Reject\\ H_0\\ |\\ H_a\\ is\\ true) = P(Type\\ II\\ error)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Law of large numbers\n",
    "\n",
    "If $Y_1,\\ Y_2\\ ...,\\ Y_n$ are independently and identically distributed (i.i.d) with mean $\\mu$ and finite variance, a sample mean converges in probability to $\\mu$.\n",
    "\n",
    "This means that for sufficiently large N, $\\bar{Y}\\ -\\ \\mu$ is ~ 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central limit theorem\n",
    "\n",
    "- If $Y_1,\\ Y_2\\ ...,\\ Y_n$ are i.i.d with mean $\\mu$ and variance $\\sigma^2$, then when *n* is large, sample mean $\\hat{\\mu}$ is approximately normally distributed with mean $\\mu$ and variance $\\frac{\\sigma^2}{n}$.\n",
    "- $\\hat{\\mu}$ is asymptotically normally distributed\n",
    "- So? Well, this allows us to assume that some random variables are normally distributed, and to make inferences about the likelihood of observations drawn from that distribution. For instance, it implies:\n",
    "\n",
    "$$\\frac{\\hat{\\mu}\\ -\\ \\mu}{\\sigma/\\sqrt{n}}\\ \\sim \\ N(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## T-tests revisited\n",
    "\n",
    "Does $\\frac{\\hat{\\mu}\\ -\\ \\mu}{\\sigma/\\sqrt{n}}$ look familiar? If we use the sample standard deviation in the denominator, that's the t-statistic!\n",
    "\n",
    "$$\\frac{\\hat{\\mu}\\ -\\ \\mu}{s/\\sqrt{n}}$$\n",
    "\n",
    "And if n is large, then the value of the t-statistic is approximately normally distributed. (If n is small and the sample observations are normally distributed, then it has a t-distribution.)\n",
    "\n",
    "$\\frac{s}{\\sqrt{n}}$ is also called the standard error, $s.e.(\\mu)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## P-values and hypothesis testing, revisited\n",
    "\n",
    "If we can assume a probability distribution, e.g. N(0,1), then we can calculate the likelihood of seeing some value given that assumption.\n",
    "\n",
    "![](./norm_dist_probs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypothesis testing with t-tests, review\n",
    "\n",
    "Let's say 1165 bootcamp applicants take a GA admissions test in 2017, with an average score of 60.86 and a standard deviation of 8.02. The expected score for all bootcamp applicants is 59. Do GA applicants have the same expected score?\n",
    "\n",
    "We can estimate $\\mu$, the GA applicant population mean, with our sample mean. $\\hat{\\mu} = \\bar{Y} = 60.86$. The sample standard deviation *s* is 8.02.\n",
    "\n",
    "Standard error of the estimate is then $se(\\hat{\\mu}) = \\frac{s}{\\sqrt{n}} = \\frac{8.02}{\\sqrt{1165}} = 0.235$\n",
    "\n",
    "> What are our null and alternative hypotheses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$H_0: \\mu = 59$$\n",
    "$$H_a: \\mu \\neq 59$$\n",
    "\n",
    "Under $H_0,\\ t = \\frac{\\hat{\\mu} - 59}{se(\\hat{\\mu})}$ is approximate normally distributed with N(0,1). If t falls far on the tail, the p-value is low and we'll reject $H_0$.\n",
    "\n",
    "Calculate the t-statistic and [look up its p-value](https://graphpad.com/quickcalcs/PValue1.cfm]).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$t = \\frac{60.86 - 59}{0.2350} = 7.915$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Again, but now with scipy ('skippy'?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.05037070851 61.1582143415\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "np.random.seed(7654567)  # fix seed to get the same result - subject of our lab\n",
    "rvs = stats.norm.rvs(loc=60.86, scale=8.02, size=(1165))\n",
    "\n",
    "# Note that the mean and std of our generated data aren't precisely the same.\n",
    "print np.std(rvs), np.mean(rvs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which scipy function to use?\n",
    "\n",
    "A few common t-tests include:\n",
    "- One-sample t-test. Used to determine whether a hypothesized population\n",
    "    mean differs significantly from an observed sample mean.\n",
    "- Two-sample t-test. Used to determine whether the difference between samples means differs significantly from the              hypothesized difference between population means.\n",
    "- Paired t-test. Used to test the significance of the difference\n",
    "    between paired means.\n",
    "\n",
    "Scipy has methods for all of these, and more. Which one do we want?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From the documentation, we want `scipy.stats.ttest_1samp`, for our one-sample t-test.\n",
    "\n",
    "To verify, compare our formula with the scipy code, [here](https://github.com/scipy/scipy/blob/v0.14.0/scipy/stats/stats.py#L3037)\n",
    "\n",
    "\n",
    "```python\n",
    " a, axis = _chk_asarray(a, axis)\n",
    "    n = a.shape[axis]\n",
    "    df = n - 1\n",
    "\n",
    "    d = np.mean(a, axis) - popmean\n",
    "    v = np.var(a, axis, ddof=1)\n",
    "    denom = np.sqrt(v / float(n))\n",
    "\n",
    "    t = np.divide(d, denom)\n",
    "    t, prob = _ttest_finish(df, t)\n",
    "\n",
    "    return t, prob\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Look good? Okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_1sampResult(statistic=9.1465051826423593, pvalue=2.5558469858139369e-19)\n",
      "Ttest_1sampResult(statistic=0.67051185169785055, pvalue=0.50266456334344989)\n"
     ]
    }
   ],
   "source": [
    "# Test if mean of random sample is equal to true mean, and different mean.\n",
    "# We reject the null hypothesis in the second case and donâ€™t reject it in the first case.\n",
    "\n",
    "print stats.ttest_1samp(rvs,59.0)\n",
    "print stats.ttest_1samp(rvs,61.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"ind-practice\"></a>\n",
    "## Independent Practice: classic t-tests (20 minutes)\n",
    "\n",
    "In pairs or trios, look at the SAT test data from Project 1. (We'll assume it's a sample of results, rather than the population results.) Together, form null and alternative hypotheses about some of the scores. \n",
    "(E.g., H0: the mean difference between states' verbal and math scores is 0; or H0: the population math score is 550.)\n",
    "\n",
    "Choose a significance level and conduct an appropriate t-test.\n",
    "\n",
    "- [t-tests](http://iaingallagher.tumblr.com/post/50980987285/t-tests-in-python)\n",
    "- [t distribution](http://stattrek.com/probability-distributions/t-distribution.aspx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Verbal</th>\n",
       "      <th>Math</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT</td>\n",
       "      <td>82</td>\n",
       "      <td>509</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NJ</td>\n",
       "      <td>81</td>\n",
       "      <td>499</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MA</td>\n",
       "      <td>79</td>\n",
       "      <td>511</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>77</td>\n",
       "      <td>495</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NH</td>\n",
       "      <td>72</td>\n",
       "      <td>520</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RI</td>\n",
       "      <td>71</td>\n",
       "      <td>501</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PA</td>\n",
       "      <td>71</td>\n",
       "      <td>500</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VT</td>\n",
       "      <td>69</td>\n",
       "      <td>511</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ME</td>\n",
       "      <td>69</td>\n",
       "      <td>506</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VA</td>\n",
       "      <td>68</td>\n",
       "      <td>510</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DE</td>\n",
       "      <td>67</td>\n",
       "      <td>501</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MD</td>\n",
       "      <td>65</td>\n",
       "      <td>508</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NC</td>\n",
       "      <td>65</td>\n",
       "      <td>493</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GA</td>\n",
       "      <td>63</td>\n",
       "      <td>491</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IN</td>\n",
       "      <td>60</td>\n",
       "      <td>499</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SC</td>\n",
       "      <td>57</td>\n",
       "      <td>486</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DC</td>\n",
       "      <td>56</td>\n",
       "      <td>482</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OR</td>\n",
       "      <td>55</td>\n",
       "      <td>526</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FL</td>\n",
       "      <td>54</td>\n",
       "      <td>498</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WA</td>\n",
       "      <td>53</td>\n",
       "      <td>527</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TX</td>\n",
       "      <td>53</td>\n",
       "      <td>493</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HI</td>\n",
       "      <td>52</td>\n",
       "      <td>485</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AK</td>\n",
       "      <td>51</td>\n",
       "      <td>514</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CA</td>\n",
       "      <td>51</td>\n",
       "      <td>498</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AZ</td>\n",
       "      <td>34</td>\n",
       "      <td>523</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NV</td>\n",
       "      <td>33</td>\n",
       "      <td>509</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CO</td>\n",
       "      <td>31</td>\n",
       "      <td>539</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>OH</td>\n",
       "      <td>26</td>\n",
       "      <td>534</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MT</td>\n",
       "      <td>23</td>\n",
       "      <td>539</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WV</td>\n",
       "      <td>18</td>\n",
       "      <td>527</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ID</td>\n",
       "      <td>17</td>\n",
       "      <td>543</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TN</td>\n",
       "      <td>13</td>\n",
       "      <td>562</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NM</td>\n",
       "      <td>13</td>\n",
       "      <td>551</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>IL</td>\n",
       "      <td>12</td>\n",
       "      <td>576</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>KY</td>\n",
       "      <td>12</td>\n",
       "      <td>550</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>WY</td>\n",
       "      <td>11</td>\n",
       "      <td>547</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MI</td>\n",
       "      <td>11</td>\n",
       "      <td>561</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MN</td>\n",
       "      <td>9</td>\n",
       "      <td>580</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KS</td>\n",
       "      <td>9</td>\n",
       "      <td>577</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AL</td>\n",
       "      <td>9</td>\n",
       "      <td>559</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NE</td>\n",
       "      <td>8</td>\n",
       "      <td>562</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>OK</td>\n",
       "      <td>8</td>\n",
       "      <td>567</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>MO</td>\n",
       "      <td>8</td>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LA</td>\n",
       "      <td>7</td>\n",
       "      <td>564</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>WI</td>\n",
       "      <td>6</td>\n",
       "      <td>584</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AR</td>\n",
       "      <td>6</td>\n",
       "      <td>562</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>UT</td>\n",
       "      <td>5</td>\n",
       "      <td>575</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IA</td>\n",
       "      <td>5</td>\n",
       "      <td>593</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SD</td>\n",
       "      <td>4</td>\n",
       "      <td>577</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ND</td>\n",
       "      <td>4</td>\n",
       "      <td>592</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>MS</td>\n",
       "      <td>4</td>\n",
       "      <td>566</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>All</td>\n",
       "      <td>45</td>\n",
       "      <td>506</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State  Rate  Verbal  Math\n",
       "0     CT    82     509   510\n",
       "1     NJ    81     499   513\n",
       "2     MA    79     511   515\n",
       "3     NY    77     495   505\n",
       "4     NH    72     520   516\n",
       "5     RI    71     501   499\n",
       "6     PA    71     500   499\n",
       "7     VT    69     511   506\n",
       "8     ME    69     506   500\n",
       "9     VA    68     510   501\n",
       "10    DE    67     501   499\n",
       "11    MD    65     508   510\n",
       "12    NC    65     493   499\n",
       "13    GA    63     491   489\n",
       "14    IN    60     499   501\n",
       "15    SC    57     486   488\n",
       "16    DC    56     482   474\n",
       "17    OR    55     526   526\n",
       "18    FL    54     498   499\n",
       "19    WA    53     527   527\n",
       "20    TX    53     493   499\n",
       "21    HI    52     485   515\n",
       "22    AK    51     514   510\n",
       "23    CA    51     498   517\n",
       "24    AZ    34     523   525\n",
       "25    NV    33     509   515\n",
       "26    CO    31     539   542\n",
       "27    OH    26     534   439\n",
       "28    MT    23     539   539\n",
       "29    WV    18     527   512\n",
       "30    ID    17     543   542\n",
       "31    TN    13     562   553\n",
       "32    NM    13     551   542\n",
       "33    IL    12     576   589\n",
       "34    KY    12     550   550\n",
       "35    WY    11     547   545\n",
       "36    MI    11     561   572\n",
       "37    MN     9     580   589\n",
       "38    KS     9     577   580\n",
       "39    AL     9     559   554\n",
       "40    NE     8     562   568\n",
       "41    OK     8     567   561\n",
       "42    MO     8     577   577\n",
       "43    LA     7     564   562\n",
       "44    WI     6     584   596\n",
       "45    AR     6     562   550\n",
       "46    UT     5     575   570\n",
       "47    IA     5     593   603\n",
       "48    SD     4     577   582\n",
       "49    ND     4     592   599\n",
       "50    MS     4     566   551\n",
       "51   All    45     506   514"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/timothyernst/GA-DSI/projects/projects-weekly/project-01/assets/sat_scores.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=-0.23803183309056899, pvalue=0.81281016714386212)\n"
     ]
    }
   ],
   "source": [
    "print stats.ttest_rel(df['Math'], df['Verbal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"t-testing\"></a>\n",
    "## Demo/Guided Practice: computational approaches (10 minutes)\n",
    "\n",
    "Now that computational power is cheap and available (and you know Python!), we have an alternative way of approaching these questions: iteratively calculate the probability of observing some result.\n",
    "\n",
    "For example:\n",
    "\n",
    "```Python\n",
    "# Simulating a binomial variable (e.g. seeing heads in 20 out of 30 coin flips )\n",
    "m = 0\n",
    "for i in range(10000):\n",
    "    trials = np.random.randint(2, size = 30)\n",
    "    if (trials.sum() >= 20):\n",
    "        m += 1\n",
    "p = m / 10000.0\n",
    "p\n",
    "```\n",
    "\n",
    "> Check: what is this doing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This was an example if **simulating** your experiment -- you can do this if you have an a priori model of what happens.\n",
    "\n",
    "If you don't have an a priori model, another option is **shuffling** results:\n",
    "\n",
    "(Example from: http://cs.nyu.edu/shasha/papers/StatisticsIsEasyExcerpt.html)\n",
    "\n",
    "\"Imagine we have given some people a placebo and others a drug. The measured improvement (the more positive the better) is\n",
    "\n",
    "Placebo: 54 51 58 44 55 52 42 47 58 46\n",
    "\n",
    "Drug: 54 73 53 70 73 68 52 65 65\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"As you can see, the drug seems more effective on the average (the average measured improvement is 63.7 for the drug and 50.7 for the placebo). But is this difference in the average real? Formula-based statistics would use a t-test which entails certain assumptions about normality and variance, but we are going to look just at the samples themselves and shuffle the labels.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What this means can be illustrated as follows. We put all the people in a table having two columns value and label (P for placebo and D for drug).\n",
    "\n",
    "| value | label |\n",
    "|:-:|---|\n",
    "|54\t| P |\n",
    "|51\t| P |\n",
    "|58\t| P |\n",
    "|44\t| P |\n",
    "|55\t| P |\n",
    "|52\t| P |\n",
    "|42\t| P |\n",
    "|47\t| P |\n",
    "|58\t| P |\n",
    "|46\t| P |\n",
    "|54\t| D |\n",
    "|73\t| D |\n",
    "|53\t| D |\n",
    "|70\t| D |\n",
    "|73\t| D |\n",
    "|68\t| D |\n",
    "|52\t| D |\n",
    "|65\t| D |\n",
    "|65\t| D |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Shuffling the labels means that we will take the Ps and Ds and randomly distribute them among the patients. (Technically, we do a uniform random permutation of the label column.)\n",
    "\n",
    "This might give:\n",
    "\n",
    "| value | label |\n",
    "|:-:|---|\n",
    "|54\t| P \n",
    "|51\t| P\n",
    "|58\t| D\n",
    "|44\t| P\n",
    "|55\t| P\n",
    "|52\t| D\n",
    "|42\t| D\n",
    "|47\t| D\n",
    "|58\t| D\n",
    "|46\t| D\n",
    "|54\t| P\n",
    "|73\t| P\n",
    "|53\t| P\n",
    "|70\t| D\n",
    "|73\t| P\n",
    "|68\t| P\n",
    "|52\t| D\n",
    "|65\t| P\n",
    "|65\t| D\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can then look at the difference in the average P value vs. the average D value here. We get an average of 59.0 for P and 54.4 for D. We repeat this shuffle-then-measure procedure 10,000 times and ask what fraction of time we get a difference between drug and placebo greater than or equal to the measured difference of 63.7 - 50.7 = 13. The answer in this case is under 0.001.\"\"\n",
    "\n",
    "> Check: what are the benefits of a computational strategy? The risks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"ind-practice\"></a>\n",
    "## Independent Practice: finding probabilities computationally (30 minutes)\n",
    "\n",
    "In pairs or trios, design and code a computational way of finding the probability of rolling a 6 at least one-third of the time on a fair die."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothyernst/anaconda/envs/Python2/lib/python2.7/site-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d8c731bc7892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# as we increase the sample size, we approach a normal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcount_6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcount_6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "trials = 10.\n",
    "data = np.random.randint(6, size = (trials,30)) # as we increase the sample size, we approach a normal distribution\n",
    "data\n",
    "count_6 = [ sum(x) for x in data if x ==5]\n",
    "count_6\n",
    "\n",
    "\n",
    "#N = np.sum(data, axis = 1) # sum up the number of heads in rows (experiments)\n",
    "#plt.hist(N)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"conclusion\"></a>\n",
    "## Conclusion (5 mins)\n",
    "\n",
    "- We make trade-offs between risking Type I and Type II errors\n",
    "- There are varieties of t-tests, and scipy methods for conducting them\n",
    "- Simulations / computation strategies are an alternative to parametric statistical inference"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Python2]",
   "language": "python",
   "name": "Python [Python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
